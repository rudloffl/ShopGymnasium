{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "432ab00b-7e82-4cd7-9463-e5e93b60b321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cellule 1 — Imports\n",
    "import numpy as np\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "275349e8-d8e6-4087-b509-933e8f6a39fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cellule 2 — Environnement V4 : production en lots, bornes 0-10, commande +5 (fixe)\n",
    "\n",
    "class WorkshopEnvV4:\n",
    "    \"\"\"\n",
    "    Modélisation 4 :\n",
    "    - Actions :\n",
    "        0 = Attendre\n",
    "        1..10 = Produire k unités de Produit 1\n",
    "        11..20 = Produire k unités de Produit 2 (k = action-10)\n",
    "        21 = Commander +5 MP (règle d'origine)\n",
    "    - Bornes :\n",
    "        stock_raw <= 10\n",
    "        stock_sell <= 10\n",
    "    - Coût de stockage : 0.5 × stock_sell\n",
    "    - Durées :\n",
    "        P1 : 1 par unité\n",
    "        P2 : 3 par unité\n",
    "        Commander : 1\n",
    "        Attendre : 1\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, max_steps=50, holding_cost=0.5):\n",
    "        self.max_steps = max_steps\n",
    "        self.holding_cost = holding_cost\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.stock_raw = np.random.randint(0, 11)   # 0-10\n",
    "        self.stock_sell = 0                         # 0-10\n",
    "        self.steps = 0\n",
    "        return (self.stock_raw, self.stock_sell)\n",
    "\n",
    "    def step(self, action):\n",
    "        reward = 0.0\n",
    "\n",
    "        # ACTION 0 — Attendre\n",
    "        if action == 0:\n",
    "            reward = -1 if self.stock_raw == 0 else 0\n",
    "            self.steps += 1\n",
    "\n",
    "        # ACTIONS 1..10 — Produire k P1\n",
    "        elif 1 <= action <= 10:\n",
    "            k = action\n",
    "            if self.stock_raw >= k:\n",
    "                self.stock_raw -= k\n",
    "                self.stock_sell = min(10, self.stock_sell + k)\n",
    "                reward = 2.0 * k\n",
    "            self.steps += k * 1\n",
    "\n",
    "        # ACTIONS 11..20 — Produire k P2\n",
    "        elif 11 <= action <= 20:\n",
    "            k = action - 10\n",
    "            cost_mp = 2 * k\n",
    "            if self.stock_raw >= cost_mp:\n",
    "                self.stock_raw -= cost_mp\n",
    "                self.stock_sell = min(10, self.stock_sell + k)\n",
    "                reward = 20.0 * k\n",
    "            self.steps += k * 3\n",
    "\n",
    "        # ACTION 21 — Commander +5 MP (règle d'origine)\n",
    "        elif action == 21:\n",
    "            self.stock_raw = min(10, self.stock_raw + 5)\n",
    "            reward = -5\n",
    "            self.steps += 1\n",
    "\n",
    "        # BORNES FINALES\n",
    "        self.stock_raw = max(0, min(10, self.stock_raw))\n",
    "        self.stock_sell = max(0, min(10, self.stock_sell))\n",
    "\n",
    "        # Coût de stockage\n",
    "        reward -= self.holding_cost * self.stock_sell\n",
    "\n",
    "        # Fin d'épisode\n",
    "        done = self.steps >= self.max_steps\n",
    "        return (self.stock_raw, self.stock_sell), reward, done, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d12e526-305b-4b92-a224-974364cd19c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cellule 3 — Instanciation de V4 (bornes 0-10 strictes)\n",
    "env = WorkshopEnvV4(max_steps=50, holding_cost=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f5b7c77-d015-4278-9dbc-9e5900d0c4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cellule 4 — Q-table et hyperparamètres\n",
    "n_states_raw = 11        # 0..10\n",
    "n_states_sell = 11       # 0..10\n",
    "n_actions = 22           # 0..21\n",
    "\n",
    "Q = np.zeros((n_states_raw, n_states_sell, n_actions))\n",
    "\n",
    "alpha = 0.1\n",
    "gamma = 0.95\n",
    "epsilon = 1.0\n",
    "epsilon_min = 0.1\n",
    "epsilon_decay = 0.995\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99b22a3b-d068-428e-8a30-fc8a47605b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cellule 5 — Politique epsilon-greedy\n",
    "def choose_action(state, epsilon):\n",
    "    sr, ss = state\n",
    "    if random.random() < epsilon:\n",
    "        return random.randint(0, n_actions - 1)\n",
    "    return int(np.argmax(Q[sr, ss, :]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2523daf-52b3-4704-84ca-3d96ae077f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 200, Reward=18.5, epsilon=0.367\n",
      "Episode 400, Reward=96.0, epsilon=0.135\n",
      "Episode 600, Reward=80.0, epsilon=0.100\n",
      "Episode 800, Reward=43.5, epsilon=0.100\n",
      "Episode 1000, Reward=174.0, epsilon=0.100\n",
      "Episode 1200, Reward=130.5, epsilon=0.100\n",
      "Episode 1400, Reward=151.5, epsilon=0.100\n",
      "Episode 1600, Reward=142.0, epsilon=0.100\n",
      "Episode 1800, Reward=18.0, epsilon=0.100\n",
      "Episode 2000, Reward=94.0, epsilon=0.100\n",
      "Episode 2200, Reward=30.5, epsilon=0.100\n",
      "Episode 2400, Reward=76.5, epsilon=0.100\n",
      "Episode 2600, Reward=144.5, epsilon=0.100\n",
      "Episode 2800, Reward=58.0, epsilon=0.100\n",
      "Episode 3000, Reward=149.5, epsilon=0.100\n",
      "Episode 3200, Reward=93.5, epsilon=0.100\n",
      "Episode 3400, Reward=168.0, epsilon=0.100\n",
      "Episode 3600, Reward=119.5, epsilon=0.100\n",
      "Episode 3800, Reward=150.0, epsilon=0.100\n",
      "Episode 4000, Reward=70.5, epsilon=0.100\n",
      "Episode 4200, Reward=117.0, epsilon=0.100\n",
      "Episode 4400, Reward=132.5, epsilon=0.100\n",
      "Episode 4600, Reward=139.0, epsilon=0.100\n",
      "Episode 4800, Reward=166.5, epsilon=0.100\n",
      "Episode 5000, Reward=109.0, epsilon=0.100\n",
      "Episode 5200, Reward=118.5, epsilon=0.100\n",
      "Episode 5400, Reward=187.5, epsilon=0.100\n",
      "Episode 5600, Reward=171.5, epsilon=0.100\n",
      "Episode 5800, Reward=141.5, epsilon=0.100\n",
      "Episode 6000, Reward=48.5, epsilon=0.100\n",
      "Episode 6200, Reward=199.0, epsilon=0.100\n",
      "Episode 6400, Reward=199.0, epsilon=0.100\n",
      "Episode 6600, Reward=98.5, epsilon=0.100\n",
      "Episode 6800, Reward=202.5, epsilon=0.100\n",
      "Episode 7000, Reward=163.5, epsilon=0.100\n",
      "Episode 7200, Reward=137.5, epsilon=0.100\n",
      "Episode 7400, Reward=135.0, epsilon=0.100\n",
      "Episode 7600, Reward=90.5, epsilon=0.100\n",
      "Episode 7800, Reward=152.5, epsilon=0.100\n",
      "Episode 8000, Reward=161.5, epsilon=0.100\n"
     ]
    }
   ],
   "source": [
    "# Cellule 6 — Boucle d’apprentissage\n",
    "n_episodes = 8000\n",
    "rewards_per_episode = []\n",
    "\n",
    "for episode in range(n_episodes):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        action = choose_action(state, epsilon)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "        sr, ss = state\n",
    "        nsr, nss = next_state\n",
    "\n",
    "        best_next = np.max(Q[nsr, nss, :])\n",
    "        Q[sr, ss, action] += alpha * (reward + gamma * best_next - Q[sr, ss, action])\n",
    "\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "\n",
    "    rewards_per_episode.append(total_reward)\n",
    "\n",
    "    if epsilon > epsilon_min:\n",
    "        epsilon *= epsilon_decay\n",
    "\n",
    "    if (episode+1) % 200 == 0:\n",
    "        print(f\"Episode {episode+1}, Reward={total_reward:.1f}, epsilon={epsilon:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47c7c193-fe39-449e-831c-a936e909e8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Politique optimale (affichage par stock_sell) ===\n",
      "\n",
      "--- stock_sell = 0 ---\n",
      "stock_raw | action optimale\n",
      "---------------------------\n",
      "0         | Commander\n",
      "1         | Commander\n",
      "2         | P2-1\n",
      "3         | P1-2\n",
      "4         | P2-2\n",
      "5         | P2-1\n",
      "6         | P2-2\n",
      "7         | P2-2\n",
      "8         | P2-4\n",
      "9         | P2-3\n",
      "10        | P2-3\n",
      "\n",
      "--- stock_sell = 1 ---\n",
      "stock_raw | action optimale\n",
      "---------------------------\n",
      "0         | Commander\n",
      "1         | P1-1\n",
      "2         | P1-1\n",
      "3         | P2-1\n",
      "4         | P1-1\n",
      "5         | P1-1\n",
      "6         | P1-1\n",
      "7         | P1-7\n",
      "8         | P1-3\n",
      "9         | P2-3\n",
      "10        | P2-3\n",
      "\n",
      "--- stock_sell = 2 ---\n",
      "stock_raw | action optimale\n",
      "---------------------------\n",
      "0         | Commander\n",
      "1         | Commander\n",
      "2         | P1-1\n",
      "3         | P2-1\n",
      "4         | P1-2\n",
      "5         | P1-1\n",
      "6         | P2-1\n",
      "7         | P2-2\n",
      "8         | P1-1\n",
      "9         | P1-7\n",
      "10        | P1-1\n",
      "\n",
      "--- stock_sell = 3 ---\n",
      "stock_raw | action optimale\n",
      "---------------------------\n",
      "0         | P1-2\n",
      "1         | P1-1\n",
      "2         | P1-2\n",
      "3         | P2-1\n",
      "4         | P2-2\n",
      "5         | P1-4\n",
      "6         | P1-1\n",
      "7         | P2-1\n",
      "8         | P1-1\n",
      "9         | P2-2\n",
      "10        | Attendre\n",
      "\n",
      "--- stock_sell = 4 ---\n",
      "stock_raw | action optimale\n",
      "---------------------------\n",
      "0         | Commander\n",
      "1         | Commander\n",
      "2         | P2-1\n",
      "3         | P1-2\n",
      "4         | P1-2\n",
      "5         | P2-2\n",
      "6         | P2-3\n",
      "7         | P1-2\n",
      "8         | Attendre\n",
      "9         | Attendre\n",
      "10        | P1-1\n",
      "\n",
      "--- stock_sell = 5 ---\n",
      "stock_raw | action optimale\n",
      "---------------------------\n",
      "0         | Commander\n",
      "1         | P1-1\n",
      "2         | P2-1\n",
      "3         | P1-3\n",
      "4         | P2-2\n",
      "5         | P1-3\n",
      "6         | P1-1\n",
      "7         | Attendre\n",
      "8         | Attendre\n",
      "9         | P2-3\n",
      "10        | P2-5\n",
      "\n",
      "--- stock_sell = 6 ---\n",
      "stock_raw | action optimale\n",
      "---------------------------\n",
      "0         | Commander\n",
      "1         | Commander\n",
      "2         | P2-1\n",
      "3         | P1-3\n",
      "4         | P1-4\n",
      "5         | P1-4\n",
      "6         | P2-3\n",
      "7         | P2-1\n",
      "8         | P1-5\n",
      "9         | P1-1\n",
      "10        | P2-1\n",
      "\n",
      "--- stock_sell = 7 ---\n",
      "stock_raw | action optimale\n",
      "---------------------------\n",
      "0         | Commander\n",
      "1         | P1-1\n",
      "2         | P2-1\n",
      "3         | P1-3\n",
      "4         | P1-3\n",
      "5         | P1-3\n",
      "6         | P1-3\n",
      "7         | Attendre\n",
      "8         | P1-1\n",
      "9         | P1-2\n",
      "10        | P1-2\n",
      "\n",
      "--- stock_sell = 8 ---\n",
      "stock_raw | action optimale\n",
      "---------------------------\n",
      "0         | Commander\n",
      "1         | P1-1\n",
      "2         | P2-1\n",
      "3         | P1-3\n",
      "4         | P1-3\n",
      "5         | P1-2\n",
      "6         | P1-1\n",
      "7         | P1-1\n",
      "8         | P1-2\n",
      "9         | P1-2\n",
      "10        | Attendre\n",
      "\n",
      "--- stock_sell = 9 ---\n",
      "stock_raw | action optimale\n",
      "---------------------------\n",
      "0         | Commander\n",
      "1         | P1-1\n",
      "2         | P1-2\n",
      "3         | P1-2\n",
      "4         | P1-1\n",
      "5         | P1-3\n",
      "6         | P1-1\n",
      "7         | P1-2\n",
      "8         | Attendre\n",
      "9         | Attendre\n",
      "10        | P1-6\n",
      "\n",
      "--- stock_sell = 10 ---\n",
      "stock_raw | action optimale\n",
      "---------------------------\n",
      "0         | Commander\n",
      "1         | P1-1\n",
      "2         | P2-1\n",
      "3         | P2-1\n",
      "4         | P1-3\n",
      "5         | P2-2\n",
      "6         | P1-1\n",
      "7         | P1-2\n",
      "8         | P1-1\n",
      "9         | P1-2\n",
      "10        | P1-3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cellule 7 — Affichage lisible par stock_sell\n",
    "\n",
    "def short_action(a):\n",
    "    if a == 0:\n",
    "        return \"Attendre\"\n",
    "    if 1 <= a <= 10:\n",
    "        return f\"P1-{a}\"\n",
    "    if 11 <= a <= 20:\n",
    "        return f\"P2-{a-10}\"\n",
    "    if a == 21:\n",
    "        return \"Commander\"\n",
    "    return \"?\"\n",
    "\n",
    "print(\"=== Politique optimale (affichage par stock_sell) ===\\n\")\n",
    "\n",
    "for ss in range(11):\n",
    "    print(f\"--- stock_sell = {ss} ---\")\n",
    "    print(\"stock_raw | action optimale\")\n",
    "    print(\"---------------------------\")\n",
    "    for sr in range(11):\n",
    "        best = np.argmax(Q[sr, ss, :])\n",
    "        print(f\"{sr:<9} | {short_action(best)}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5612c6c-58af-47f1-bbbf-2112532ba09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Synthèse métier automatique ===\n",
      "\n",
      "1. Zones où l'agent choisit de COMMANDER (action 21)\n",
      "   → Décisions: 14\n",
      "   → États concernés: (sr=0, ss=0), (sr=0, ss=1), (sr=0, ss=2), (sr=0, ss=4), (sr=0, ss=5), (sr=0, ss=6), (sr=0, ss=7), (sr=0, ss=8), (sr=0, ss=9), (sr=0, ss=10), (sr=1, ss=0), (sr=1, ss=2), (sr=1, ss=4), (sr=1, ss=6) \n",
      "\n",
      "2. Zones où l'agent choisit d'ATTENDRE (action 0)\n",
      "   → Décisions: 9\n",
      "   → États concernés: (sr=7, ss=5), (sr=7, ss=7), (sr=8, ss=4), (sr=8, ss=5), (sr=8, ss=9), (sr=9, ss=4), (sr=9, ss=9), (sr=10, ss=3), (sr=10, ss=8) \n",
      "\n",
      "3. Zones où l'agent produit du PRODUIT 1 (actions 1..10)\n",
      "   → Décisions: 64\n",
      "   → États concernés: (sr=0, ss=3), (sr=1, ss=1), (sr=1, ss=3), (sr=1, ss=5), (sr=1, ss=7), (sr=1, ss=8), (sr=1, ss=9), (sr=1, ss=10), (sr=2, ss=1), (sr=2, ss=2), (sr=2, ss=3), (sr=2, ss=9), (sr=3, ss=0), (sr=3, ss=4), (sr=3, ss=5), (sr=3, ss=6), (sr=3, ss=7), (sr=3, ss=8), (sr=3, ss=9), (sr=4, ss=1)... \n",
      "\n",
      "4. Zones où l'agent produit du PRODUIT 2 (actions 11..20)\n",
      "   → Décisions: 34\n",
      "   → États concernés: (sr=2, ss=0), (sr=2, ss=4), (sr=2, ss=5), (sr=2, ss=6), (sr=2, ss=7), (sr=2, ss=8), (sr=2, ss=10), (sr=3, ss=1), (sr=3, ss=2), (sr=3, ss=3), (sr=3, ss=10), (sr=4, ss=0), (sr=4, ss=3), (sr=4, ss=5), (sr=5, ss=0), (sr=5, ss=4), (sr=5, ss=10), (sr=6, ss=0), (sr=6, ss=2), (sr=6, ss=4)... \n",
      "\n",
      "=== Interprétation automatique (résumé métier) ===\n",
      "\n",
      "• L'agent commande dans des situations inattendues → à vérifier.\n",
      "• Le modèle privilégie le Produit 1 : logique prudente dictée par les coûts de stockage.\n",
      "• Le Produit 1 est utilisé comme régulateur : petites productions lorsque stock_sell est élevé.\n",
      "• L'action 'Attendre' apparaît dans les zones de stock_sell élevé : éviter le surstock et la pénalité.\n",
      "\n",
      "=== Fin de la synthèse ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cellule 8 — Synthèse métier intelligente \n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# Classification des comportements\n",
    "zones = {\n",
    "    \"Commander\": [],\n",
    "    \"Attendre\": [],\n",
    "    \"P1\": [],\n",
    "    \"P2\": []\n",
    "}\n",
    "\n",
    "# Analyse de la politique optimale\n",
    "for sr in range(11):\n",
    "    for ss in range(11):\n",
    "        best = np.argmax(Q[sr, ss, :])\n",
    "\n",
    "        if best == 21:\n",
    "            zones[\"Commander\"].append((sr, ss))\n",
    "        elif best == 0:\n",
    "            zones[\"Attendre\"].append((sr, ss))\n",
    "        elif 1 <= best <= 10:\n",
    "            zones[\"P1\"].append((sr, ss))\n",
    "        elif 11 <= best <= 20:\n",
    "            zones[\"P2\"].append((sr, ss))\n",
    "\n",
    "# Construction d'une synthèse claire\n",
    "def format_states(lst):\n",
    "    \"\"\"Affiche les états sous forme compacte, ex: (sr=2, ss=0), (sr=3, ss=1)...\"\"\"\n",
    "    return \", \".join([f\"(sr={s[0]}, ss={s[1]})\" for s in lst[:20]]) + \\\n",
    "           (\"...\" if len(lst) > 20 else \"\")\n",
    "\n",
    "print(\"\\n=== Synthèse métier automatique ===\\n\")\n",
    "\n",
    "print(\"1. Zones où l'agent choisit de COMMANDER (action 21)\")\n",
    "print(\"   → Décisions:\", len(zones[\"Commander\"]))\n",
    "print(\"   → États concernés:\", format_states(zones[\"Commander\"]), \"\\n\")\n",
    "\n",
    "print(\"2. Zones où l'agent choisit d'ATTENDRE (action 0)\")\n",
    "print(\"   → Décisions:\", len(zones[\"Attendre\"]))\n",
    "print(\"   → États concernés:\", format_states(zones[\"Attendre\"]), \"\\n\")\n",
    "\n",
    "print(\"3. Zones où l'agent produit du PRODUIT 1 (actions 1..10)\")\n",
    "print(\"   → Décisions:\", len(zones[\"P1\"]))\n",
    "print(\"   → États concernés:\", format_states(zones[\"P1\"]), \"\\n\")\n",
    "\n",
    "print(\"4. Zones où l'agent produit du PRODUIT 2 (actions 11..20)\")\n",
    "print(\"   → Décisions:\", len(zones[\"P2\"]))\n",
    "print(\"   → États concernés:\", format_states(zones[\"P2\"]), \"\\n\")\n",
    "\n",
    "# Résumé métier global basé sur la structure observée\n",
    "print(\"=== Interprétation automatique (résumé métier) ===\\n\")\n",
    "\n",
    "# Commande MP\n",
    "if all(sr == 0 for sr, ss in zones[\"Commander\"]):\n",
    "    print(\"• L'agent ne commande que lorsque le stock de MP est à 0 → politique rationnelle. \")\n",
    "else:\n",
    "    print(\"• L'agent commande dans des situations inattendues → à vérifier.\")\n",
    "\n",
    "# P2 dominance\n",
    "if len(zones[\"P2\"]) > len(zones[\"P1\"]):\n",
    "    print(\"• Le modèle privilégie massivement le Produit 2 lorsque le stock_sell est bas : logique de forte rentabilité.\")\n",
    "else:\n",
    "    print(\"• Le modèle privilégie le Produit 1 : logique prudente dictée par les coûts de stockage.\")\n",
    "\n",
    "# P1 usage\n",
    "print(\"• Le Produit 1 est utilisé comme régulateur : petites productions lorsque stock_sell est élevé.\")\n",
    "\n",
    "# Attente\n",
    "if len(zones[\"Attendre\"]) > 0:\n",
    "    print(\"• L'action 'Attendre' apparaît dans les zones de stock_sell élevé : éviter le surstock et la pénalité.\")\n",
    "else:\n",
    "    print(\"• Aucune attente détectée → le coût de stockage est trop faible pour générer une prudence.\")\n",
    "\n",
    "print(\"\\n=== Fin de la synthèse ===\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95b91dd-f96d-4e27-adb7-06990f1e3f97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:qlearning]",
   "language": "python",
   "name": "conda-env-qlearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
